{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>fieldname</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collaterals</td>\n",
       "      <td>collateral_id</td>\n",
       "      <td>Collateral Identification Number</td>\n",
       "      <td>int8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collaterals</td>\n",
       "      <td>type</td>\n",
       "      <td>Collateral Type</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collaterals</td>\n",
       "      <td>orig_value</td>\n",
       "      <td>Original Value of Collateral</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corporations_data</td>\n",
       "      <td>corp_name</td>\n",
       "      <td>Corporation Name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corporations_data</td>\n",
       "      <td>zip_code</td>\n",
       "      <td>Zip Code</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               table      fieldname                             label  \\\n",
       "0        collaterals  collateral_id  Collateral Identification Number   \n",
       "1        collaterals           type                   Collateral Type   \n",
       "2        collaterals     orig_value      Original Value of Collateral   \n",
       "3  corporations_data      corp_name                  Corporation Name   \n",
       "4  corporations_data       zip_code                          Zip Code   \n",
       "\n",
       "       type  \n",
       "0      int8  \n",
       "1  category  \n",
       "2     float  \n",
       "3       str  \n",
       "4  category  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the highlighted part of the path as a separate variable\n",
    "root_path = r\"C:\\datapipes\\data\"\n",
    "csv_files = ['facilities.csv', 'collaterals.csv', 'counterparties.csv']\n",
    "csv_dfs = [file_name.replace('.csv', '') for file_name in csv_files]\n",
    "\n",
    "# Initialize an empty dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate through the CSV files\n",
    "for file in csv_files:\n",
    "    # Remove the \".csv\" extension from the file name\n",
    "    file_name = os.path.splitext(file)[0]\n",
    "    file_path = os.path.join(root_path, file)\n",
    "    # Check if the file exists before reading it\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        dataframes[file_name] = pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"File '{file}' does not exist in the specified path.\")\n",
    "\n",
    "# Read the metadata.csv into a DataFrame\n",
    "metadata_df = pd.read_csv(os.path.join(root_path, 'metadata.csv'))\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All csv_files values are found in unique_tables. \n",
      "\n",
      "DATAFRAME in the iteration:  facilities \n",
      "\n",
      "The metadata dictionary with columns and data types\n",
      "{'facility_id': 'int8', 'counterparty_id': 'int8', 'start_date': 'datetime64', 'end_date': 'datetime64', 'facility_type': 'category', 'amount': 'float'} \n",
      "\n",
      "Column types without category type >>\n",
      "facility_id                  int8\n",
      "counterparty_id              int8\n",
      "start_date         datetime64[ns]\n",
      "end_date           datetime64[ns]\n",
      "facility_type              object\n",
      "amount                    float64\n",
      "dtype: object \n",
      "\n",
      "Column types with category type >>\n",
      "facility_id                  int8\n",
      "counterparty_id              int8\n",
      "start_date         datetime64[ns]\n",
      "end_date           datetime64[ns]\n",
      "facility_type            category\n",
      "amount                    float64\n",
      "dtype: object \n",
      "\n",
      "Memory Usage without category type: 92895 bytes\n",
      "Memory Usage with category type: 27576 bytes \n",
      "\n",
      "DATAFRAME in the iteration:  collaterals \n",
      "\n",
      "The metadata dictionary with columns and data types\n",
      "{'collateral_id': 'int8', 'type': 'category', 'orig_value': 'float'} \n",
      "\n",
      "Column types without category type >>\n",
      "collateral_id       int8\n",
      "type              object\n",
      "orig_value       float64\n",
      "dtype: object \n",
      "\n",
      "Column types with category type >>\n",
      "collateral_id        int8\n",
      "type             category\n",
      "orig_value        float64\n",
      "dtype: object \n",
      "\n",
      "Memory Usage without category type: 34204 bytes\n",
      "Memory Usage with category type: 5436 bytes \n",
      "\n",
      "DATAFRAME in the iteration:  counterparties \n",
      "\n",
      "The metadata dictionary with columns and data types\n",
      "{'counterparty_id': 'int8', 'name': 'str', 'city': 'category', 'state': 'category', 'zip': 'category', 'country': 'category'} \n",
      "\n",
      "Column types without category type >>\n",
      "counterparty_id      int8\n",
      "name               object\n",
      "city               object\n",
      "state              object\n",
      "zip                object\n",
      "country            object\n",
      "dtype: object \n",
      "\n",
      "Column types with category type >>\n",
      "counterparty_id        int8\n",
      "name                 object\n",
      "city               category\n",
      "state              category\n",
      "zip                category\n",
      "country            category\n",
      "dtype: object \n",
      "\n",
      "Memory Usage without category type: 214063 bytes\n",
      "Memory Usage with category type: 148605 bytes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of unique table names within the metadata\n",
    "unique_tables = list(metadata_df['table'].unique())\n",
    "\n",
    "# Check if all unique_tables values are found in csv_files\n",
    "if not set(csv_dfs).issubset(unique_tables):\n",
    "    missing_tables = set(csv_dfs) - set(unique_tables)\n",
    "    print(f\"The following unique_tables values are not found in metadata_df table values: {missing_tables}\")\n",
    "else:\n",
    "    print(\"All csv_files values are found in unique_tables.\", \"\\n\")\n",
    "\n",
    "    dataframes_clean = {}\n",
    "    dataframes_clean_nocat = {}\n",
    "\n",
    "    for table_name in csv_dfs:\n",
    "        print(\"DATAFRAME in the iteration: \", table_name, \"\\n\")\n",
    "        subset_metadata_df = metadata_df[metadata_df['table'] == table_name]\n",
    "\n",
    "        # Convert the DataFrame to a dictionary {field_name: data_type}\n",
    "        metadata_dict = pd.Series(subset_metadata_df.type.values, index=subset_metadata_df.fieldname).to_dict()\n",
    "\n",
    "        print(\"The metadata dictionary with columns and data types\")\n",
    "        print(metadata_dict, \"\\n\")\n",
    "\n",
    "        table = dataframes[table_name]\n",
    "        table_nocat = dataframes[table_name].copy()\n",
    "\n",
    "        # Convert each column to the specified data type - categorical types are not included\n",
    "        for i, (fieldname, dtype) in enumerate(metadata_dict.items()):\n",
    "            if dtype == 'datetime64':\n",
    "                table_nocat[fieldname] = pd.to_datetime(table_nocat[fieldname])\n",
    "            elif dtype == 'category':\n",
    "                table_nocat[fieldname] = table_nocat[fieldname].astype('object')\n",
    "            else:\n",
    "                table_nocat[fieldname] = table_nocat[fieldname].astype(dtype)\n",
    "        # Stack dataframes into a dictionary\n",
    "        dataframes_clean_nocat[table_name] = table_nocat\n",
    "\n",
    "        # Convert each column to the specified data type - including categorical types\n",
    "        for fieldname, dtype in metadata_dict.items():\n",
    "            if dtype == 'datetime64':\n",
    "                table[fieldname] = pd.to_datetime(table[fieldname])\n",
    "            else:\n",
    "                table[fieldname] = table[fieldname].astype(dtype)\n",
    "        \n",
    "        # Stack dataframes into a dictionary\n",
    "        dataframes_clean[table_name] = table\n",
    "\n",
    "        # Now the dataframe has columns types as specified in metadata_dict\n",
    "        print(\"Column types without category type >>\")\n",
    "        print(dataframes_clean_nocat[table_name].dtypes, \"\\n\")\n",
    "        print(\"Column types with category type >>\")\n",
    "        print(dataframes_clean[table_name].dtypes, \"\\n\")\n",
    "\n",
    "        # Calculate the memory usage of the DataFrame\n",
    "        memory_usage_nocat = dataframes_clean_nocat[table_name].memory_usage(deep=True).sum()\n",
    "        memory_usage = dataframes_clean[table_name].memory_usage(deep=True).sum()\n",
    "        # Print the memory usage in bytes\n",
    "        print(\"Memory Usage without category type:\", memory_usage_nocat, \"bytes\")\n",
    "        print(\"Memory Usage with category type:\", memory_usage, \"bytes\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facility_id                  int8\n",
       "counterparty_id              int8\n",
       "start_date         datetime64[ns]\n",
       "end_date           datetime64[ns]\n",
       "facility_type              object\n",
       "amount                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facilities = dataframes_clean['facilities']\n",
    "facilities[\"facility_type\"] = facilities[\"facility_type\"].astype('object')\n",
    "facilities.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
